#!/usr/bin/env python

# Copyright (c) 2016 ZTE Corp and others.
#
# All rights reserved. This program and the accompanying materials
# are made available under the terms of the Apache License, Version 2.0
# which accompanies this distribution, and is available at
# http://www.apache.org/licenses/LICENSE-2.0

# pylint: disable=too-many-instance-attributes

"""Define the parent classes of all Xtesting Features.

Feature is considered as TestCase offered by Third-party. It offers
helpers to run any python method or any bash command.
"""

import csv
import logging
import os
import time

from xtesting.core import testcase
from xtesting.core import feature

__author__ = ("Vincent Mahe <v.mahe@orange.com>, "
              "Cedric Ollivier <cedric.ollivier@orange.com>")


class MTSLauncher(feature.BashFeature):
    """Class designed to run any bash command."""

    __logger = logging.getLogger(__name__)
    mts_install_dir = "/opt/mts"

    def __init__(self, **kwargs):
        super(MTSLauncher, self).__init__(**kwargs)
        self.result_file = "{}/{}.log".format(self.res_dir, self.case_name)
        # Location of the HTML report generated by MTS
        self.mts_stats_dir = os.path.join(self.res_dir, 'mts_stats_report')
        # Location of the log files generated by MTS for each test.
        # Need to end path with a separator because of a bug in MTS.
        self.mts_logs_dir = os.path.join(self.res_dir,
                                         'mts_logs' + os.path.sep)
        # The location of file named testPlan.csv that it always in $MTS_HOME/logs
        self.mts_result_csv_file = self.mts_install_dir + os.path.sep
        self.mts_result_csv_file += ("logs" + os.path.sep + "testPlan.csv")
        self.total_tests = 0
        self.pass_tests = 0
        self.fail_tests = 0
        self.skip_tests = 0
        self.response = None

    def parse_results(self):
        """Parse testPlan.csv containing the status of each testcase of the test file.
        See sample file in `xtesting/samples/mts/output/testPlan.csv`
        """
        with open(self.mts_result_csv_file) as stream_:
            self.__logger.info("Parsing file : %s", self.mts_result_csv_file)
            reader = csv.reader(stream_, delimiter=';')
            rownum = 0
            _tests_data = []
            # self.response = json.load(stream_)
            for row in reader:
                _test_dict = {}
                nb_values = len(row)
                if rownum > 0:
                    # If there's only one delimiter, it is the name of the <test> elt
                    if nb_values == 2:
                        test_name = row[0]
                        self.__logger.info(
                            "-------------------------------------------------------")
                        self.__logger.info("MTS <test> name : %s", test_name)
                        _test_dict['parent'] = test_name
                    elif nb_values == 3:
                        testcase_name = row[0].lstrip()
                        testcase_status = row[2]
                        self.__logger.info(
                            "  MTS <testcase> name : %s --> status : %s", testcase_name,
                            testcase_status)
                        self.total_tests += 1
                        if testcase_status == 'OK':
                            self.pass_tests += 1
                        elif testcase_status == 'Failed':
                            self.fail_tests += 1
                        elif testcase_status == '?':
                            self.skip_tests += 1
                        _test_dict['status'] = testcase_status
                        _test_dict['name'] = testcase_name
                rownum += 1
                _tests_data.append(_test_dict)

            try:
                self.result = 100 * (
                    self.pass_tests / self.total_tests)
            except ZeroDivisionError:
                self.__logger.error("No test has been run")

            self.details = {}
            self.details['description'] = "Execution of some MTS tests"
            self.details['total_tests'] = self.total_tests
            self.details['pass_tests'] = self.pass_tests
            self.details['fail_tests'] = self.fail_tests
            self.details['skip_tests'] = self.skip_tests
            self.details['tests'] = _tests_data

    def execute(self, **kwargs):
        """Execute the cmd passed as arg

        Args:
            kwargs: Arbitrary keyword arguments.

        Returns:
            0 if cmd returns 0,
            -1 otherwise.
        """
        try:
            # Read specific parameters for MTS
            test_file = kwargs["test_file"]
            log_level = kwargs["log_level"] if "log_level" in kwargs else "INFO"
            store_method = kwargs[
                "store_method"] if "store_method" in kwargs else "FILE"
            # java_mem = kwargs["java_memory"] if "java_memory" in kwargs else 1024
            # Build command line to launch for MTS
            cmd = ("./startCmd.sh {} -sequential -levelLog:{} -storageLog:{}"
                   " -config:stats.REPORT_DIRECTORY+{}"
                   " -config:logs.STORAGE_DIRECTORY+{}"
                   " -genReport:true"
                   " -showRep:false").format(test_file,
                                             log_level,
                                             store_method,
                                             self.mts_stats_dir,
                                             self.mts_logs_dir)
            # Must use the $HOME_MTS/bin as current working dir
            cwd = self.mts_install_dir + os.path.sep + "bin"

            # Make sure to create the necessary output sub-folders for MTS
            if not os.path.isdir(self.mts_stats_dir):
                os.makedirs(self.mts_stats_dir)
            if not os.path.isdir(self.mts_logs_dir):
                os.makedirs(self.mts_logs_dir)

            return super().execute(cmd=cmd, cwd=cwd)

        except KeyError:
            self.__logger.error("Missing mandatory arg for MTS. kwargs: %s", kwargs)
        return -1

    def run(self, **kwargs):
        """Run the feature.

        It allows executing any Python method by calling execute().

        It sets the following attributes required to push the results
        to DB:

            * result,
            * start_time,
            * stop_time.

        It doesn't fulfill details when pushing the results to the DB.

        Args:
            kwargs: Arbitrary keyword arguments.

        Returns:
            TestCase.EX_OK if execute() returns 0,
            TestCase.EX_RUN_ERROR otherwise.
        """
        self.start_time = time.time()
        exit_code = testcase.TestCase.EX_RUN_ERROR
        self.result = 0
        try:
            if self.execute(**kwargs) == 0:
                exit_code = testcase.TestCase.EX_OK

                try:
                    self.parse_results()
                    self.__logger.info("-------------------------------------------------------")
                    self.__logger.info(
                        "Result file testPlan.csv in $MTS_HOME/logs was successfully parsed")
                except Exception:  # pylint: disable=broad-except
                    self.__logger.exception("Cannot parse result file $MTS_HOME/logs/testPlan.csv")
                    exit_code = testcase.TestCase.EX_RUN_ERROR
        except Exception:  # pylint: disable=broad-except
            self.__logger.exception("%s FAILED", self.project_name)
        self.stop_time = time.time()
        return exit_code
